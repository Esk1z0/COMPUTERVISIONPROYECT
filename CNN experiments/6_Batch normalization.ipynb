{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "QYuALZOG-AMq",
    "tags": []
   },
   "source": [
    "## Assignment: Image recognition\n",
    "- Alumno 1:\n",
    "- Alumno 2:\n",
    "- Alumno 3:\n",
    "\n",
    "The goals of the assignment are:\n",
    "* Develop proficiency in using Tensorflow/Keras for training Neural Nets (NNs).\n",
    "* Put into practice the acquired knowledge to optimize the parameters and architecture of a feedforward Neural Net (ffNN), in the context of an image recognition problem.\n",
    "* Put into practice NNs specially conceived for analysing images. Design and optimize the parameters of a Convolutional Neural Net (CNN) to deal with previous task.\n",
    "* Train popular architectures from scratch (e.g., GoogLeNet, VGG, ResNet, ...), and compare the results with the ones provided by their pre-trained versions using transfer learning.\n",
    "\n",
    "Follow the link below to download the classification data set  “xview_recognition”: [https://drive.upm.es/s/2DDPE2zHw5dbM3G](https://drive.upm.es/s/2DDPE2zHw5dbM3G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-26T00:00:21.031186Z",
     "start_time": "2024-10-26T00:00:17.131476Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "editable": true,
    "execution": {
     "iopub.execute_input": "2025-09-18T08:27:59.622636Z",
     "iopub.status.busy": "2025-09-18T08:27:59.622372Z",
     "iopub.status.idle": "2025-09-18T08:28:13.071424Z",
     "shell.execute_reply": "2025-09-18T08:28:13.070171Z"
    },
    "executionInfo": {
     "elapsed": 9912,
     "status": "ok",
     "timestamp": 1759687663156,
     "user": {
      "displayName": "Jimmy “Jimmy”",
      "userId": "16087473281499178535"
     },
     "user_tz": -120
    },
    "id": "i7H8WLjBzB2n",
    "outputId": "d5027c76-e627-45d5-ff51-2f270bbe7d2f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME='CNN/6_batch_normalization'\n",
    "assert(not EXPERIMENT_NAME is None)\n",
    "\n",
    "import tensorflow as tf\n",
    "import uuid\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import rasterio\n",
    "import json\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "# Reduce TF warnings\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Activation, Rescaling\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import RandomFlip, RandomRotation, RandomZoom\n",
    "from tensorflow.keras.layers import Dense, Flatten, Input, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import TerminateOnNaN, ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "%matplotlib inline\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_PATH = \"/workspace/COMPUTERVISIONPROYECT\"\n",
    "DATASET_NAME = 'stratified'\n",
    "\n",
    "# XVIEW_RECOGNITION_PATH = \"./data/xview_recognition/\"\n",
    "XVIEW_RECOGNITION_PATH = os.path.join(PROJECT_PATH, \"data/xview_recognition\")\n",
    "\n",
    "EXPERIMENT_PATH = os.path.join(PROJECT_PATH, \"experiment_results\", EXPERIMENT_NAME)\n",
    "EXPERIMENT_RESULTS = os.path.join(EXPERIMENT_PATH, \"results\")\n",
    "assert(not os.path.exists(EXPERIMENT_PATH))\n",
    "if not os.path.exists(EXPERIMENT_PATH):\n",
    "    os.mkdir(EXPERIMENT_PATH)\n",
    "    os.mkdir(EXPERIMENT_RESULTS)\n",
    "CHECKPOINT_DIR = os.path.join(EXPERIMENT_PATH, 'model_checkpoints')\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "BEST_WEIGHTS_FILENAME_PATTERN = os.path.join(CHECKPOINT_DIR, 'epoch_{epoch:03d}-val_loss_{val_loss:.4f}.keras')\n",
    "MODEL_PATH = os.path.join(EXPERIMENT_PATH, 'model.keras')\n",
    "\n",
    "CM_PATH = os.path.join(EXPERIMENT_RESULTS, 'cm.png')\n",
    "METRICS_PATH = os.path.join(EXPERIMENT_RESULTS, 'metrics.csv')\n",
    "ACC_LOSS_PATH = os.path.join(EXPERIMENT_RESULTS, 'acc_loss.png')\n",
    "TEST_PREDICTS_PATH = os.path.join(EXPERIMENT_RESULTS, 'prediction.json')\n",
    "HISTORY_PATH = os.path.join(EXPERIMENT_RESULTS, 'history.csv')\n",
    "\n",
    "TRAIN_SET_FILENAME = '_'.join([DATASET_NAME, 'train.tfrecord'])\n",
    "VALIDATION_SET_FILENAME = '_'.join([DATASET_NAME, 'validation.tfrecord'])\n",
    "TRAIN_SET_PATH = os.path.join(XVIEW_RECOGNITION_PATH, TRAIN_SET_FILENAME)\n",
    "VALIDATION_SET_PATH = os.path.join(XVIEW_RECOGNITION_PATH, VALIDATION_SET_FILENAME)\n",
    "\n",
    "## Hyperparameters\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 1e-3\n",
    "WEIGHT_DECAY = None\n",
    "DROPOUT_RATE = 0.9\n",
    "REGULARIZER_PENALTY = None\n",
    "DATA_AUGMENTATAION_RATE = 0.2\n",
    "EPOCHS = 40\n",
    "\n",
    "categories = {0: 'Cargo plane', 1: 'Small car', 2: 'Bus', 3: 'Truck', 4: 'Motorboat', 5: 'Fishing vessel', 6: 'Dump truck', 7: 'Excavator', 8: 'Building', 9: 'Helipad', 10: 'Storage tank', 11: 'Shipping container', 12: 'Pylon'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Required classes and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-26T00:00:21.066937Z",
     "start_time": "2024-10-26T00:00:21.059126Z"
    },
    "editable": true,
    "execution": {
     "iopub.execute_input": "2025-09-18T08:28:13.076611Z",
     "iopub.status.busy": "2025-09-18T08:28:13.076007Z",
     "iopub.status.idle": "2025-09-18T08:28:13.083344Z",
     "shell.execute_reply": "2025-09-18T08:28:13.082866Z"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1759687663176,
     "user": {
      "displayName": "Jimmy “Jimmy”",
      "userId": "16087473281499178535"
     },
     "user_tz": -120
    },
    "id": "OYtqD3Oh-AMw",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GenericObject:\n",
    "    \"\"\"\n",
    "    Generic object data.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.id = uuid.uuid4()\n",
    "        self.bb = (-1, -1, -1, -1)\n",
    "        self.category= -1\n",
    "        self.score = -1\n",
    "\n",
    "class GenericImage:\n",
    "    \"\"\"\n",
    "    Generic image data.\n",
    "    \"\"\"\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "        self.tile = np.array([-1, -1, -1, -1])  # (pt_x, pt_y, pt_x+width, pt_y+height)\n",
    "        self.objects = list([])\n",
    "\n",
    "    def add_object(self, obj: GenericObject):\n",
    "        self.objects.append(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_confusion_matrix(cm, categories, save_path=None, exp_name=None):\n",
    "    # Draw confusion matrix\n",
    "    fig = plt.figure(figsize=[3.2*pow(len(categories), 0.5), 2.4*pow(len(categories), 0.5)])\n",
    "    ax = fig.add_subplot(111)\n",
    "    cm = cm.astype('float') / np.maximum(cm.sum(axis=1)[:, np.newaxis], np.finfo(np.float64).eps)\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=plt.colormaps['Blues'])\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    ax.set(xticks=np.arange(cm.shape[1]), yticks=np.arange(cm.shape[0]), xticklabels=list(categories.values()), yticklabels=list(categories.values()), ylabel='Annotation', xlabel='Prediction')\n",
    "    # Rotate the tick labels and set their alignment\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "    # Loop over data dimensions and create text annotations\n",
    "    thresh = cm.max() / 2.0\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], '.2f'), ha=\"center\", va=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\", fontsize=int(15-pow(len(categories), 0.5)))\n",
    "    fig.tight_layout()\n",
    "\n",
    "    if save_path:\n",
    "        if exp_name:\n",
    "            plt.title(exp_name)\n",
    "        plt.savefig(save_path, bbox_inches='tight', dpi=300)\n",
    "        print(f\"Gráfico guardado en: {save_path}\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# 0. La usamos para las imágenes de test\n",
    "def load_geoimage(filename_tensor):\n",
    "    warnings.filterwarnings('ignore', category=rasterio.errors.NotGeoreferencedWarning)\n",
    "    filename = filename_tensor\n",
    "    src_raster = rasterio.open(filename, 'r')\n",
    "\n",
    "    input_type = src_raster.profile['dtype']\n",
    "    input_channels = src_raster.count\n",
    "    img = np.zeros((src_raster.height, src_raster.width, src_raster.count), dtype=input_type)\n",
    "    for band in range(input_channels):\n",
    "        img[:, :, band] = src_raster.read(band+1)\n",
    "    return img\n",
    "\n",
    "# 1. Función para decodificar los ejemplos del archivo\n",
    "def _parse_image_function(example_proto):\n",
    "    feature_description = {\n",
    "        'height': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'width': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'depth': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'category_id': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
    "    }\n",
    "    \n",
    "    features = tf.io.parse_single_example(example_proto, feature_description)\n",
    "    \n",
    "    image = tf.io.decode_raw(features['image_raw'], out_type=tf.uint8)\n",
    "    shape = [features['height'], features['width'], features['depth']]\n",
    "    image = tf.reshape(image, shape)\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    \n",
    "    image = tf.image.resize(image, [224, 224])\n",
    "    \n",
    "    category_id = tf.cast(features['category_id'], tf.int32)\n",
    "    label = tf.one_hot(category_id, depth=len(categories))\n",
    "    \n",
    "    return image, label\n",
    "\n",
    "# 2. Función para crear el dataset\n",
    "def create_tfrecord_dataset(filenames, batch_size, do_shuffle=False):\n",
    "    # Lee los archivos TFRecord. Puede leer de múltiples archivos en paralelo.\n",
    "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=tf.data.AUTOTUNE)\n",
    "    \n",
    "    dataset = dataset.map(_parse_image_function, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.cache()\n",
    "    \n",
    "    if do_shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=1000)\n",
    "\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = create_tfrecord_dataset([TRAIN_SET_PATH], BATCH_SIZE, do_shuffle=True)\n",
    "valid_dataset = create_tfrecord_dataset([VALIDATION_SET_PATH], BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_labels = []\n",
    "for _,label_idxs in train_dataset:\n",
    "    y_train_labels += list(label_idxs.numpy().argmax(axis=1))\n",
    "\n",
    "index,freqs = np.unique(y_train_labels, return_counts=True)\n",
    "categories_count = pd.Series(freqs, index=[categories[idx] for idx in index], name='Size').sort_values(ascending=False)\n",
    "\n",
    "categories_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = Sequential([\n",
    "    RandomFlip(\"horizontal\"),\n",
    "    RandomRotation(DATA_AUGMENTATAION_RATE),\n",
    "    RandomZoom(DATA_AUGMENTATAION_RATE),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "diNBB3qy-AM2"
   },
   "source": [
    "# Training\n",
    "Design and train a ffNN to deal with the “xview_recognition” classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 761
    },
    "executionInfo": {
     "elapsed": 1848,
     "status": "ok",
     "timestamp": 1759687665824,
     "user": {
      "displayName": "Jimmy “Jimmy”",
      "userId": "16087473281499178535"
     },
     "user_tz": -120
    },
    "id": "Hby939K1WvZy",
    "outputId": "0d07705a-3ccd-4e4b-af42-debc9c17fdc6"
   },
   "outputs": [],
   "source": [
    "model = Sequential(name=EXPERIMENT_NAME)\n",
    "model.add(Input(shape=(224, 224, 3)))\n",
    "model.add(data_augmentation)\n",
    "model.add(Rescaling(1./255))\n",
    "\n",
    "# Feature extraction layer\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D((2, 2), name='Pool1'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D((2, 2), name='Pool2'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D((2, 2), name='Pool3'))\n",
    "\n",
    "model.add(Flatten(name='Flatten'))\n",
    "\n",
    "model.add(Dropout(DROPOUT_RATE))\n",
    "\n",
    "# Classification layer\n",
    "model.add(Dense(512, activation='relu'))\n",
    "\n",
    "model.add(Dense(len(categories), activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-26T00:00:25.467525Z",
     "start_time": "2024-10-26T00:00:25.434068Z"
    },
    "execution": {
     "iopub.execute_input": "2025-09-18T08:28:16.337697Z",
     "iopub.status.busy": "2025-09-18T08:28:16.337546Z",
     "iopub.status.idle": "2025-09-18T08:28:16.351042Z",
     "shell.execute_reply": "2025-09-18T08:28:16.350124Z"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1759687665849,
     "user": {
      "displayName": "Jimmy “Jimmy”",
      "userId": "16087473281499178535"
     },
     "user_tz": -120
    },
    "id": "-aSlKtG6-AM7"
   },
   "outputs": [],
   "source": [
    "opt = Adam(learning_rate=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "model.compile(\n",
    "    optimizer=opt,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-26T00:00:26.254555Z",
     "start_time": "2024-10-26T00:00:26.243908Z"
    },
    "execution": {
     "iopub.execute_input": "2025-09-18T08:28:16.352904Z",
     "iopub.status.busy": "2025-09-18T08:28:16.352762Z",
     "iopub.status.idle": "2025-09-18T08:28:16.356742Z",
     "shell.execute_reply": "2025-09-18T08:28:16.356290Z"
    },
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1759687665863,
     "user": {
      "displayName": "Jimmy “Jimmy”",
      "userId": "16087473281499178535"
     },
     "user_tz": -120
    },
    "id": "GGAJEfpB-AM8"
   },
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    filepath=BEST_WEIGHTS_FILENAME_PATTERN,\n",
    "    monitor='val_loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True\n",
    ")\n",
    "reduce_lr = ReduceLROnPlateau('val_accuracy', factor=0.5, patience=5, verbose=1, min_lr=1e-6)\n",
    "terminate = TerminateOnNaN()\n",
    "early_stop = EarlyStopping('val_accuracy', patience=EPOCHS, verbose=1, restore_best_weights=False)\n",
    "callbacks = [model_checkpoint, reduce_lr, early_stop, terminate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 304741,
     "status": "ok",
     "timestamp": 1759687970646,
     "user": {
      "displayName": "Jimmy “Jimmy”",
      "userId": "16087473281499178535"
     },
     "user_tz": -120
    },
    "id": "IWUfJ9fiYa6H",
    "outputId": "89cbc010-88e3-4fc2-e8c3-d06d1c6b4b94"
   },
   "outputs": [],
   "source": [
    "print('Training model')\n",
    "h = model.fit(train_dataset, \n",
    "              validation_data=valid_dataset, \n",
    "              epochs=EPOCHS, \n",
    "              callbacks=callbacks, \n",
    "              verbose=1)\n",
    "\n",
    "history_df = pd.DataFrame(model.history.history).reset_index(names=['epoch'])\n",
    "history_df['checkpoint'] = False\n",
    "\n",
    "checkpoints = glob.glob(os.path.join(CHECKPOINT_DIR, '*.keras'))\n",
    "\n",
    "if checkpoints:\n",
    "    # Copiamos el mejor modelo en la ruta {EXPERIMENT_PATH}/model.keras\n",
    "    # Ordenar los archivos por el valor de 'val_loss' (que está en el nombre)\n",
    "    # y coger el primero (el que tenga el valor más bajo)\n",
    "    BEST_WEIGHTS_FILENAME = min(checkpoints, key=lambda x: float(x.split('val_loss_')[1].replace('.keras', '')))\n",
    "    model.load_weights(BEST_WEIGHTS_FILENAME)\n",
    "    model.save(MODEL_PATH)\n",
    "\n",
    "    checkpoint_epochs = [int(ruta.split('/')[-1].split('-val_loss')[0].replace('epoch_', ''))-1 for ruta in checkpoints]\n",
    "    history_df.loc[checkpoint_epochs, 'checkpoint'] = True\n",
    "\n",
    "    print(f\"El mejor modelo se encuentra en: {MODEL_PATH}\")\n",
    "else:\n",
    "    print(\"No se encontraron checkpoints.\")\n",
    "\n",
    "history_df.to_csv(HISTORY_PATH, index=False)\n",
    "print(f\"El historial se encuentra en: {HISTORY_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "8IMMO_mT-AM9",
    "tags": []
   },
   "source": [
    "# Validation\n",
    "Compute validation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(valid_dataset)\n",
    "category_names = np.array(list(categories.values()))\n",
    "y_pred = category_names[predictions.argmax(axis=1)]\n",
    "\n",
    "y_true = []\n",
    "\n",
    "for images_batch, labels_batch in valid_dataset:\n",
    "    labels_np = labels_batch.numpy()\n",
    "    \n",
    "    true_indices = np.argmax(labels_np, axis=1)\n",
    "    batch_labels = category_names[true_indices]\n",
    "    \n",
    "    y_true.extend(batch_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 954
    },
    "execution": {
     "iopub.execute_input": "2025-09-18T13:01:22.019704Z",
     "iopub.status.busy": "2025-09-18T13:01:22.019551Z",
     "iopub.status.idle": "2025-09-18T13:01:22.740150Z",
     "shell.execute_reply": "2025-09-18T13:01:22.739387Z"
    },
    "executionInfo": {
     "elapsed": 1278,
     "status": "ok",
     "timestamp": 1759688142465,
     "user": {
      "displayName": "Jimmy “Jimmy”",
      "userId": "16087473281499178535"
     },
     "user_tz": -120
    },
    "id": "F_FmeGytzB2y",
    "outputId": "84f8d5e1-a52e-432a-f836-f9d10a237ca1"
   },
   "outputs": [],
   "source": [
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred, labels=list(categories.values()))\n",
    "draw_confusion_matrix(cm, categories, CM_PATH, EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-09-18T13:01:22.742591Z",
     "iopub.status.busy": "2025-09-18T13:01:22.742443Z",
     "iopub.status.idle": "2025-09-18T13:01:22.750853Z",
     "shell.execute_reply": "2025-09-18T13:01:22.749931Z"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1759688142471,
     "user": {
      "displayName": "Jimmy “Jimmy”",
      "userId": "16087473281499178535"
     },
     "user_tz": -120
    },
    "id": "I1Ash4SUzB2y",
    "outputId": "10ff3d16-b18c-4db4-c2aa-321a7b33e0f6"
   },
   "outputs": [],
   "source": [
    "ll = []\n",
    "# Compute the accuracy\n",
    "correct_samples_class = np.diag(cm).astype(float)\n",
    "total_samples_class = np.sum(cm, axis=1).astype(float)\n",
    "total_predicts_class = np.sum(cm, axis=0).astype(float)\n",
    "print('Mean Accuracy: %.3f%%' % (np.sum(correct_samples_class) / np.sum(total_samples_class) * 100))\n",
    "acc = correct_samples_class / np.maximum(total_samples_class, np.finfo(np.float64).eps)\n",
    "global_acc = acc.mean()\n",
    "print('Mean Recall: %.3f%%' % (acc.mean() * 100))\n",
    "acc = correct_samples_class / np.maximum(total_predicts_class, np.finfo(np.float64).eps)\n",
    "global_recall = acc.mean()\n",
    "print('Mean Precision: %.3f%%' % (acc.mean() * 100))\n",
    "global_precision = acc.mean()\n",
    "for idx in range(len(categories)):\n",
    "    # True/False Positives (TP/FP) refer to the number of predicted positives that were correct/incorrect.\n",
    "    # True/False Negatives (TN/FN) refer to the number of predicted negatives that were correct/incorrect.\n",
    "    tp = cm[idx, idx]\n",
    "    fp = sum(cm[:, idx]) - tp\n",
    "    fn = sum(cm[idx, :]) - tp\n",
    "    tn = sum(np.delete(sum(cm) - cm[idx, :], idx))\n",
    "    # True Positive Rate: proportion of real positive cases that were correctly predicted as positive.\n",
    "    recall = tp / np.maximum(tp+fn, np.finfo(np.float64).eps)\n",
    "    # Precision: proportion of predicted positive cases that were truly real positives.\n",
    "    precision = tp / np.maximum(tp+fp, np.finfo(np.float64).eps)\n",
    "    # True Negative Rate: proportion of real negative cases that were correctly predicted as negative.\n",
    "    specificity = tn / np.maximum(tn+fp, np.finfo(np.float64).eps)\n",
    "    # Dice coefficient refers to two times the intersection of two sets divided by the sum of their areas.\n",
    "    # Dice = 2 |A∩B| / (|A|+|B|) = 2 TP / (2 TP + FP + FN)\n",
    "    f1_score = 2 * ((precision * recall) / np.maximum(precision+recall, np.finfo(np.float64).eps))\n",
    "    ll.append(pd.Series([recall, precision, specificity, f1_score], name=categories[idx], index=[\"Recall\", \"Precision\", \"Specificity\", \"F1 Score\"]))\n",
    "ll = pd.DataFrame(ll)\n",
    "sizes_col=pd.Series(y_true).value_counts()\n",
    "sizes_col.name=\"Size\"\n",
    "ll = pd.concat([sizes_col, ll, pd.Series([EXPERIMENT_NAME for _ in categories], name='Experiment', index=categories.values())],axis=1)\n",
    "ll.index.name='Category'\n",
    "ll = ll.reset_index().set_index(['Experiment','Category'])\n",
    "ll['Accuracy'] = np.nan\n",
    "ll.loc[(EXPERIMENT_NAME, 'Global'), ['Size', 'Recall', 'Precision', 'Accuracy']] = [ll.Size.sum().astype(int), global_recall, global_precision, global_acc]\n",
    "ll = ll.sort_values('Size', ascending=False)\n",
    "ll.to_csv(METRICS_PATH)\n",
    "ll.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "plt.title(f'Accuracy & Loss - {EXPERIMENT_NAME}')\n",
    "ax1.set_xlabel('Epoch')\n",
    "\n",
    "color_acc = 'blue'\n",
    "ax1.set_ylabel('Accuracy', color=color_acc)\n",
    "ax1.plot(h.history['accuracy'], label='Train Accuracy', color='blue', marker='.')\n",
    "ax1.plot(h.history['val_accuracy'], label='Validation Accuracy', color='tab:blue', linestyle='--', marker='.')\n",
    "ax1.tick_params(axis='y', labelcolor=color_acc)\n",
    "ax1.grid(True, linestyle='--', alpha=0.5)\n",
    "ax1.set_ylim((0,1))\n",
    "\n",
    "ax2 = ax1.twinx()  \n",
    "color_loss = 'orange'\n",
    "ax2.set_ylabel('Loss', color=color_loss)\n",
    "ax2.plot(h.history['loss'], label='Train Loss', color='orange', marker='.')\n",
    "ax2.plot(h.history['val_loss'], label='Validation Loss', color='tab:orange', linestyle='--', marker='.')\n",
    "ax2.tick_params(axis='y', labelcolor=color_loss)\n",
    "lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "\n",
    "ax1.legend(lines1 + lines2, labels1 + labels2, loc='center left', frameon=True, fontsize='small')\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.savefig(ACC_LOSS_PATH, bbox_inches='tight', dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H0ppnBZszB2z"
   },
   "source": [
    "# Testing\n",
    "Try to improve the results provided in the competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-09-18T13:01:22.753680Z",
     "iopub.status.busy": "2025-09-18T13:01:22.753432Z",
     "iopub.status.idle": "2025-09-18T13:01:22.832351Z",
     "shell.execute_reply": "2025-09-18T13:01:22.831293Z"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1759688142476,
     "user": {
      "displayName": "Jimmy “Jimmy”",
      "userId": "16087473281499178535"
     },
     "user_tz": -120
    },
    "id": "tJr_-xCt-AM-",
    "outputId": "e94f95ba-5f33-45a2-f306-fa73f4c0e8cb"
   },
   "outputs": [],
   "source": [
    "anns = []\n",
    "for (dirpath, dirnames, filenames) in os.walk(os.path.join(XVIEW_RECOGNITION_PATH, 'xview_test')):\n",
    "    for filename in filenames:\n",
    "        image = GenericImage(os.path.join(dirpath,filename))\n",
    "        image.tile = np.array([0, 0, 224, 224])\n",
    "        obj = GenericObject()\n",
    "        obj.bb = (0, 0, 224, 224)\n",
    "        obj.category = dirpath[dirpath.rfind('/')+1:]\n",
    "        image.add_object(obj)\n",
    "        anns.append(image)\n",
    "print('Number of testing images: ' + str(len(anns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-18T13:01:22.837502Z",
     "iopub.status.busy": "2025-09-18T13:01:22.837113Z",
     "iopub.status.idle": "2025-09-18T13:03:24.835373Z",
     "shell.execute_reply": "2025-09-18T13:03:24.834773Z"
    },
    "executionInfo": {
     "elapsed": 208096,
     "status": "ok",
     "timestamp": 1759688825442,
     "user": {
      "displayName": "Jimmy “Jimmy”",
      "userId": "16087473281499178535"
     },
     "user_tz": -120
    },
    "id": "TGs2zqfv-AM_"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(MODEL_PATH)\n",
    "predictions_data = {\"images\": {}, \"annotations\": {}}\n",
    "for idx, ann in enumerate(anns):\n",
    "    image_data = {\"image_id\": ann.filename.split('/')[-1], \"filename\": ann.filename, \"width\": int(ann.tile[2]), \"height\": int(ann.tile[3])}\n",
    "    predictions_data[\"images\"][idx] = image_data\n",
    "    # Load image\n",
    "    image = load_geoimage(ann.filename)\n",
    "    for obj_pred in ann.objects:\n",
    "        # Generate prediction\n",
    "        warped_image = np.expand_dims(image, 0)\n",
    "        predictions = model.predict(warped_image, verbose=0)\n",
    "        # Save prediction\n",
    "        pred_category = list(categories.values())[np.argmax(predictions)]\n",
    "        pred_score = np.max(predictions)\n",
    "        annotation_data = {\"image_id\": ann.filename.split('/')[-1], \"category_id\": pred_category, \"bbox\": [int(x) for x in obj_pred.bb]}\n",
    "        predictions_data[\"annotations\"][idx] = annotation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-18T13:03:24.837935Z",
     "iopub.status.busy": "2025-09-18T13:03:24.837770Z",
     "iopub.status.idle": "2025-09-18T13:03:24.871502Z",
     "shell.execute_reply": "2025-09-18T13:03:24.870824Z"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1759688825444,
     "user": {
      "displayName": "Jimmy “Jimmy”",
      "userId": "16087473281499178535"
     },
     "user_tz": -120
    },
    "id": "fbJbKTB0zB20"
   },
   "outputs": [],
   "source": [
    "with open(TEST_PREDICTS_PATH, \"w\") as outfile:\n",
    "    json.dump(predictions_data, outfile)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
